{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12d1fdb4-29ce-49d2-aed9-5b62b4311662",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Procesamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb8fcab-cbf9-4fde-9194-5a9f040d93ab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Carga de dataset preprocesado mediante consultas SQL dentro de bigquery\n",
    "\n",
    "Importa **librerías** clave para:\n",
    "+ Manipular datos (pandas).\n",
    "+ Conectarse a BigQuery y leer datos (google.cloud.bigquery).\n",
    "+ Entrenar modelos de ML (sklearn, xgboost).\n",
    "+ Evaluar resultados (accuracy_score, classification_report).\n",
    "+ Visualizar datos (matplotlib).\n",
    "\n",
    "Se define una **función** traer_datos() que:\n",
    "+ Se conecta a Google BigQuery.\n",
    "+ Ejecuta una consulta SQL para extraer datos de la tabla antel-equipo4.desafio_antel.sesiones_agregadas.\n",
    "+ Convierte los resultados en un DataFrame de pandas para su análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9c4c31-b091-44bc-9ff9-1d31ac5ca5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from google.cloud.bigquery_storage import BigQueryReadClient\n",
    "from sklearn.model_selection import train_test_split \n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "def traer_datos():\n",
    "    client = bigquery.Client()\n",
    "    bqstorage_client = BigQueryReadClient()\n",
    "    query = \"\"\"\n",
    "    SELECT *\n",
    "    FROM `antel-equipo4.desafio_antel.sesiones_agregadas`\n",
    "    \"\"\"\n",
    "    df = client.query(query).to_dataframe(bqstorage_client=bqstorage_client)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39415172-f92f-46fa-a815-83635d8c7899",
   "metadata": {},
   "source": [
    "## Conversión de las variables categóricas en valores númericos para poder llevar a cabo el modelo de machine learning\n",
    "Para ejecutar el modelo de machine learning todas las variables deben ser númericas por lo que las variables horario del día y plataforma usada deben ser transformadas. Como el modelo a usar no es redes neuronales, no es necesario normalizar las variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6966a5-6c62-4172-a303-513df6d1b025",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def variables_categoricas_procesamiento(df):\n",
    "    columnas_cat = ['horario_del_dia', 'plataforma_usada']\n",
    "    for col in columnas_cat:\n",
    "        df[col] = df[col].astype('category').cat.codes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a31805e-3970-4280-ba83-b63b1f2fb3fc",
   "metadata": {},
   "source": [
    "## Definición de la función para la matriz de correlación\n",
    "Se ejecuta matriz de correlación para realizar un análisis de las variables por separado, y poder realizar recomendaciones en base a las correlaciones de las variables, por ejemplo si el horario del día está muy correlacionado con el play, recomendar el uso de ads en ciertos horarios específicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51cfe84-99a4-4228-9626-dfb62f779d37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def obtener_matriz_correlacion(df):\n",
    "    df_correlacion = df.drop(columns=['session_id'])\n",
    "    matriz_correlacion = df_correlacion.corr()\n",
    "    return matriz_correlacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc39532-4c72-4587-b23b-3fae0e558208",
   "metadata": {},
   "source": [
    "## División datos en train, validation, y test\n",
    "Se divide el dataset en 60,20 y 20, no se evalúa la posibilidad de realizar validacion cruzada debido a que el dataset es muy grande y es mas confiable dividir los datos de esta manera para no tener sobreajuste. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c25693b-9627-40d1-a178-29d562936a90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def division_datos(df):\n",
    "    df_sesiones = df.dropna(subset=['play'])\n",
    "    X = df_sesiones.drop('play', axis=1)  \n",
    "    y = df_sesiones['play']  \n",
    "    \n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp)\n",
    "\n",
    "    # Se tiene 60% train, 20% val, 20% test\n",
    "    # Sacamos la columna de session id porque no sirve para predecir\n",
    "    X_train = X_train.drop(columns=[\"session_id\"])\n",
    "    X_test = X_test.drop(columns=[\"session_id\"])\n",
    "    X_val = X_val.drop(columns=[\"session_id\"])\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e540d8-d76c-4c73-b9e0-ccc43600cde7",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Definición de modelos de predicción a utilizar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65c6ab5-c4ad-43f0-aa62-36d7c027d020",
   "metadata": {},
   "source": [
    "A continuación se definen diferentes modelos que fueron utilizados para la predicción. Ambos sirven para evaluar la importancia de las features consideradas. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db12b90-1cda-4670-954d-206aaba536cc",
   "metadata": {},
   "source": [
    "## Gradient boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a71101d-ffb8-4d7b-baed-c722420adabf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def xgboost(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    model = xgb.XGBClassifier(\n",
    "        objective='binary:logistic',\n",
    "        eval_metric='logloss',\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        n_estimators=100,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train,eval_set=[(X_val, y_val)])\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    importancia_variables(X_train, model)\n",
    "    \n",
    "    disp = PartialDependenceDisplay.from_estimator(\n",
    "        model,\n",
    "        X_train,\n",
    "        ['eventos_unicos_sesion'],\n",
    "        kind='average'\n",
    "    )\n",
    "    disp.figure_.set_size_inches(10, 6)\n",
    "    disp.figure_.suptitle('Partial Dependence Plot para eventos unicos por sesion', y=1.02)\n",
    "\n",
    "    disp.figure_.savefig(\"eventos_unicos_sesion_dependence.png\", bbox_inches='tight')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadf6981-b299-489c-b9a8-2837dd2d47a2",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41fad90-7416-457c-96ee-45f6a583012b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_forest(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "def cross_validation(X_train, X_val, X_test, y_train, y_val, y_test):\n",
    "    param_grid = {\n",
    "        'max_depth': [4, 6, 8],\n",
    "        'n_estimators': [100, 200],\n",
    "        'learning_rate': [0.05, 0.1]\n",
    "    }\n",
    "\n",
    "    grid = GridSearchCV(\n",
    "        estimator=xgb.XGBClassifier(objective='binary:logistic', eval_metric='logloss'),\n",
    "        param_grid=param_grid,\n",
    "        scoring='f1',\n",
    "        cv=3,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    grid.fit(X_train, y_train)\n",
    "    print(\"Mejores hiperparámetros:\", grid.best_params_)\n",
    "    print(\"Mejor F1:\", grid.best_score_)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51ca536-696a-4680-9913-366514c3151c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Análisis de los resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b95c63-f950-4ef0-92dd-43b9743463ed",
   "metadata": {},
   "source": [
    "## Definición de una función para conocer la importancia de las features\n",
    "Resulta de gran importancia conocer la **importancia** de las features que toma el modelo para poder darle mayor protagonismo a las features mas importantes a la hora del análisis de datos. De todos modos, en este caso las features más importantes no tienen tanto valor para esto ya que consisten en la cantidad de eventos que tiene cada sesión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6e6ddd-cec7-497c-9135-6ad66b112381",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def importancia_variables(X_train, model):\n",
    "    importancias = pd.DataFrame({\n",
    "        'feature': X_train.columns,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values(by='importance', ascending=False)\n",
    "\n",
    "    print(importancias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0b356f-a3c6-475e-bfe5-217b0bb31600",
   "metadata": {},
   "source": [
    "## Muestra los resultados del entrenamiento del modelo y lo guarda\n",
    "En este notebook se ejecuta el modelo y se devuelve la matriz de correlación y los resultados de accuracy y otras métricas. También guarda el modelo en formato **joblib** para poder luego ser descargado por ANTEL para próximos usos del modelo.\n",
    "Las correlaciones obtenidas con la columna play son las siguientes:\n",
    "eventos_unicos_sesion\t0.758\tMuy fuerte correlación positiva.\n",
    "\n",
    "screen_view_count\t0.337\tCorrelación positiva moderada.\n",
    "\n",
    "user_engagement_count\t0.244\tCorrelación positiva débil.\n",
    "\n",
    "plataforma_usada\t0.116\tCorrelación positiva muy débil.\n",
    "\n",
    "total_eventos_sesion\t0.262\tCorrelación positiva débil.\n",
    "\n",
    "tuvo_view_item\t0.088\tPrácticamente nula (pero positiva).\n",
    "\n",
    "primera_hora\t0.030\tPrácticamente nula.\n",
    "\n",
    "duracion_sesion_segundos\t0.003\tSin relación.\n",
    "\n",
    "horario_del_dia\t-0.051\tCorrelación negativa muy débil.\n",
    "\n",
    "A grandes rasgos lo que sugiere esta informacion es que cuanto más tiempo esta el usuario en la app, más chances tiene de dar play a algún item. También hay una correlacion considerable entre el play y la plataforma usada, lo que puede significar que la interfaz para una plataforma es mas amigable que la otra. Tambien se puede deber simplemente a una tendencia social en la cual los usuarios de android tienden a usar mas la app que los de ios. La correlacion entre el horario del dia tambien es considerable y se puede interpretar que en los horarios nocturnos la gente tiende a usar menos la app.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7a9950-9e6f-4a21-a561-fa4bf50c3648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "from joblib import dump, load\n",
    "def main():\n",
    "    df = traer_datos()\n",
    "    #print(f\"Cantidad de filas: {len(df)}\")\n",
    "    df_procesado = variables_categoricas_procesamiento(df)\n",
    "    matriz_correlacion = obtener_matriz_correlacion(df_procesado)\n",
    "    print(f\"Matriz correlacion: {matriz_correlacion}\")\n",
    "    print(matriz_correlacion.to_string())\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = division_datos(df_procesado)\n",
    "    print(\"Modelo xgboost\")\n",
    "    model = xgboost(X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "    print(\"Modelo random forest\")\n",
    "    random_forest(X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "    print(\"Cross validation xgboost\")\n",
    "    #cross_validation(X_train, X_val, X_test, y_train, y_val, y_test)\n",
    "    joblib.dump(model, 'modelo_entrenado.joblib')\n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e63504-7163-468d-9c56-cf596fffcf61",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cargar el modelo pronto para usarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3550c2a0-a48d-4dad-a242-7519ecef48f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = joblib.load(modelo_entrenado.joblib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76595392-f2e0-4390-9aaf-a3b820592d87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497295e8-7185-4284-bb60-1ab13494eeac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
